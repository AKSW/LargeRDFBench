This page provides details about how one can use the BigRDFBench java tool (BigRDFBench-F1_Measure.jar) to calculate Precision, Recall, and F1 scores for a qiven SPARQL query. The main aim of this tool is to measure the completeness and correctness of results retrieved by the underlying federation engine for a given SPARQL query. First, we explain how this tool can be used with BigRDFBench, followed by the details how one can use it for any other benchmark. 

 === Using with BigRDFBench ===

 * Download the Java [https://drive.google.com/file/d/0BzemFAUFXpqOSmtQRy04OHdtelU/edit?usp=sharing BigRDFBench-F1_Measure.jar] and include into the underlying federation engine jar libraries. The complete source code for this tool can also be checkout from SVN link http://bigrdfbench.googlecode.com/svn/trunk/. 
 * Download the BigRDFBench actual [https://drive.google.com/file/d/0BzemFAUFXpqOMWlMRFNyT3lzSTQ/edit?usp=sharing results] (NTripples) file and store it into a directory.
 * Load the above results.nt file into in-memory sesame index by calling the  ResultsLoader.loadResults(ResultsFileLocation) function. This is one time process and you dont  need to load every time you run a query. 
 * You can compute the Precision, Recall, and F1 score by calling the function StatsGenerator.getFscores(BigRDFBenchQueryNo, QueryResultSetIterator). 
 * You can retrieve the results missed by federation engine (if any) by calling the function StatsGenerator.getMissingResults(BigRDFBenchQueryNo, QueryResultSetIterator

A sample code (FedX based) for retrieving the Precision, Recall and F1 scores of BigRDFBench query no S2 is given below. 

String S2 = "SELECT ?party ?page  WHERE {  <http://dbpedia.org/resource/Barack_Obama> 
<http://dbpedia.org/ontology/party> ?party .
?x <http://data.nytimes.com/elements/topicPage> ?page .
?x <http://www.w3.org/2002/07/owl#sameAs> <http://dbpedia.org/resource/Barack_Obama> .}";
			

String results = "D:/BigRDFBench/completeness_correctness/results.nt";

ResultsLoader.loadResults(results);

TupleQuery query = repo.getConnection().prepareTupleQuery(QueryLanguage.SPARQL, S2); 

TupleQueryResult res = query.evaluate();

System.out.println(StatsGenerator.getFscores("S2", res));

A sample output is given below. 

Precision: 1.0, Recall: 1.0, F1: 1.0

=== Using with any other Benchamrk===
In order to use with other bechmarks, the following extra steps are required:
 * Store all of the benchmark queries in a directory with one file per query.
 * Store the corresponding actual results of queries into another directory with one file per query results in tabular format (See sample [https://drive.google.com/file/d/0BzemFAUFXpqOMVJTV2ZoT2Q3U0U/edit?usp=sharing here] for both steps) 
 * Convert the query results into RDF NTripples by calling the function ResultsRDFizer.generateRDFResults(String queriesLocation, String resultsLocation, String outputLocation). The output file name will be results.nt
 * Repeat BigRDFBench steps explained above.

It is important to note that this tool is still at an early stage and yet not properly tested. Further more, it is highly sensitive to character encoding (UTF-8 is used). It is also important to note that Precision and F1 scores are not valid if SPARQL LIMIT clause is used in the query. This is because the results comes in random other until the specified LIMIT is reached. 